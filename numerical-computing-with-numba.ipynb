{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Accelerating Numerical Python with Numba\n",
    "\n",
    "### Madpy Meetup\n",
    "September 12, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `$ whoami`\n",
    "\n",
    "- James Bourbeau\n",
    "- Software Engineer at Quansight\n",
    "- Active in the Python data science ecosystem\n",
    "- jrbourbeau on GitHub / @\\_\\_jrbourbeau\\_\\_ on Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "- [TL;DR](#TL;DR)\n",
    "\n",
    "- [Background](#Background)\n",
    "\n",
    "    - [Python code execution](#Python-code-execution)\n",
    "    \n",
    "    - [Why is Python slow sometimes?](#Why-is-Python-slow-sometimes?)\n",
    "    \n",
    "    - [NumPy](#NumPy)\n",
    "\n",
    "- [Numba](#Numba)\n",
    "\n",
    "    - [Overview](#Overview)\n",
    "    \n",
    "    - [User interface](#User-interface)\n",
    "    \n",
    "    - [How Numba works](#How-Numba-works)\n",
    "    \n",
    "    - [When things go wrong$^*$](#When-things-go-wrong$^*$)\n",
    "    \n",
    "    - [Additional `jit` options](#Additional-jit-options)\n",
    "    \n",
    "    - [Generating custom `ufunc`s with `@vectorize`](#Generating-custom-ufuncs-with-@vectorize)\n",
    "    \n",
    "    - [Where and when to use Numba](#Where-and-when-to-use-Numba)\n",
    "\n",
    "- [Numba in action! UMAP](#Numba-in-action!-UMAP)\n",
    "\n",
    "- [Summary](#Summary)\n",
    "\n",
    "- [References](#References)\n",
    "\n",
    "- [Resources](#Resources)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# TL;DR\n",
    "\n",
    "[ [Back to top](#Outline) ]\n",
    "\n",
    "We have a `calculate()` function which performs some computation we're interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(a):\n",
    "    trace = 0.0\n",
    "    for i in range(a.shape[0]):\n",
    "        trace += np.cos(a[i, i])\n",
    "    return a + trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10_000).reshape(100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can measure how long this calculation takes using the `%timeit` magic command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_python = %timeit -o calculate(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To speed things up, we use Numba's `@jit` decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def calculate_numba(a):\n",
    "    trace = 0\n",
    "    for i in range(a.shape[0]):\n",
    "        trace += np.cos(a[i, i])\n",
    "    return a + trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_numba(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How much does adding `@jit` speed things up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "time_numba = %timeit -o calculate_numba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "time_python.average / time_numba.average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "üéâ ‚ö° üêç Hooray, we got a significant performance improvement with minimal code changes!\n",
    "\n",
    "But you may be asking yourself: what if we just used NumPy for the entire calculation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_numpy(a):\n",
    "    return a + np.cos(np.diagonal(a)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_numpy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_numpy = %timeit -o calculate_numpy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_numpy.average / time_numba.average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the Numba version is actually faster than using just NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Background\n",
    "\n",
    "[ [Back to top](#Outline) ]\n",
    "\n",
    "## Python code execution\n",
    "\n",
    "Python is sometimes referred to as an interpreted language, meaning source code is translated to native machine instructions which are executed by the interpreter. However, this isn't the whole story. Python source code is first compiled to lower-level instructions called bytecode. These bytecode instructions are then executed by the Python interpreter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/bytecode.svg\"\n",
    "         align=\"center\"\n",
    "         width=\"45%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `dis` module in the standard library to inspect bytecode for Python source code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dis import dis\n",
    "\n",
    "dis(add)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above bytecode instructions tell the Python interpreter to:\n",
    "\n",
    "- The first `LOAD_FAST` instruction pushes a reference to the local variable `x` onto the top of the stack\n",
    "- The second `LOAD_FAST` instruction pushes a reference to the local variable `y` onto the top of the stack\n",
    "- `BINARY_ADD` pops the top two items off the stack (here `x` and `y`), adds them together, then places the result on the top of the stack\n",
    "- The `RETURN_VALUE` instruction returns the value on the top of the stack\n",
    "\n",
    "Going back to our `calculate` function, we can see what that bytecode looks like too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis(calculate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are (as expected) more instructions and things are more complex in this case, but it's nice to see the building blocks for how Python code is executed.\n",
    "\n",
    "For a full list of bytcode instructions, see the [`dis` module documentation](https://docs.python.org/library/dis.html). As a side note, bytecode instructions are handled by the `switch` statement beginning on [line 1064](https://github.com/python/cpython/blob/e09359112e250268eca209355abeb17abf822486/Python/ceval.c#L1064) of `Python/ceval.c`. It's kind of fun to go through and see how things are handled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Why is Python slow sometimes?\n",
    "\n",
    "Python is a dynamically typed language in which variables are really just names that point to Python objects. This lets us do things like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1        # a is pointing to the integer 1\n",
    "a = 'whoa'   # now a is point to the string 'whoa'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is great for writing flexible code with low development overhead. However, Python's dynamic typing comes at the cost of the Python interpreter not knowing the type of variables (e.g. interger vs. floating-point vs. string) ahead of time.\n",
    "\n",
    "For example, we can compare an integer in C vs. and integer in Python:\n",
    "\n",
    "<center>\n",
    "    <img src=\"images/c-int-vs-python-int.svg\"\n",
    "         align=\"center\"\n",
    "         width=\"65%\">\n",
    "</center>\n",
    "\n",
    "\n",
    "Adding two integers in C looks like:\n",
    "\n",
    "```c\n",
    "/* C code */\n",
    "int a = 1;\n",
    "int b = 2;\n",
    "int c = a + b;\n",
    "```\n",
    "\n",
    "Because C is statically typed, the compiler knows `a`, `b`, and `c` are all integers by their very definition. So the addition `a + b` can be done very efficiently.\n",
    "\n",
    "The corresponding operation in Python looks like:\n",
    "\n",
    "\n",
    "```python\n",
    "# Python code\n",
    "a = 1\n",
    "b = 2\n",
    "c = a + b\n",
    "```\n",
    "\n",
    "Looking at the [source code](https://github.com/python/cpython/blob/e09359112e250268eca209355abeb17abf822486/Python/ceval.c#L1272-L1296) for how Python executes the `BINARY_ADD` bytecode instruction, you'll see that there is a lot of type checking to ensure the addition operation is carried out properly. This dynamic type checking adds additional overhead to Python that's doesn't exist in statically-typed langues like C. This overhead isn't a big deal if we're just adding two numbers, but can become a performance bottleneck in scientific computing applications where we might be adding two numbers 10,000,000 times.\n",
    "\n",
    "For further discussion about why Python can be slower than compiled languages, see Jake VanderPlas' great [Why Python is Slow: Looking Under the Hood](https://jakevdp.github.io/blog/2014/05/09/why-python-is-slow/) blog post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy\n",
    "\n",
    "NumPy is a Python library for efficient numerical computing in Python. It's a foundational piece of the open source Python data science ecosystem. Other libraries like SciPy, Pandas, Scikit-lean, matplotlib, Dask, and many more build on top of NumPy. \n",
    "\n",
    "NumPy consists primarily of three major components: the `ndarray` object, a paradigm for efficiently operating on arrays, and a rich library of array functions. \n",
    "\n",
    "#### `ndarray` object\n",
    "\n",
    "The NumPy `ndarray` is a multidimensional, homogeneous array of fixed-size items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3, 4], [5, 6, 7, 8]], dtype=np.float64)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.shape)\n",
    "print(a.dtype)\n",
    "print(a.strides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Universal functions\n",
    "\n",
    "NumPy has a \"universal function\" (or `ufunc`) paradigm for efficiently operating on NumPy arrays (potentially of different number of dimensions). `ufunc`s operate on arrays in an element-by-element fashion, support array broadcasting, type casting, and several other nice features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3, 4])\n",
    "b = np.array([5, 6, 7, 8])\n",
    "\n",
    "np.add(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the `np.add` `ufunc` to an equivalent straightforward operation with Python `for`-loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.random(2_000)\n",
    "b = np.random.random(2_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "\n",
    "c = np.empty(1_000, dtype=np.int64)\n",
    "for idx in range(1_000):\n",
    "    c[idx] = a[idx] + b[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit c = np.add(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ufunc`s are so performant because they push looping code down into statically-typed, compiled code in NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large collections of array functions\n",
    "\n",
    "In addition to all the standard basic math operations (`+`, `-`, `*`, `/`), NumPy also implements lots of additional functionality:\n",
    "\n",
    "- Linear algebra (e.g. SVD, least squares, etc.)\n",
    "- Special math functions (e.g. sin, cos, exp/log, polynomials)\n",
    "- Logical (boolean) operations (e.g. logical and, logical or)\n",
    "- Random number generation\n",
    "- etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.random((5, 5))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sin(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.det(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In summary: NumPy is great.** It underpins most of Python's scientific computing world. However, like everything, it has its limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy's limitations\n",
    "\n",
    "At one point or another, in particular if you're implementing custom algorithms or data processing pipelines, you'll come up against NumPy's limits:\n",
    "\n",
    "- Not every operation you may want to use is implemented as a `ufunc`\n",
    "\n",
    "- Looping over individual array elements is very slow, but is sometimes unavoidable\n",
    "\n",
    "- Combining several NumPy `ufunc`s into a large expression can be both hard to read and still too slow\n",
    "\n",
    "- NumPy (mostly) does not use the parallel execution capabilities of your computer\n",
    "\n",
    "However, there's good news. These limitations can be addressed using Numba!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center id=\"Numba\">\n",
    "    <img src=\"images/numba-blue-horizontal-rgb.svg\"\n",
    "         width=\"60%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "[ [Back to top](#Outline) ]\n",
    "\n",
    "Numba is an [open source](https://github.com/numba/numba) **just-in-time**, **type-specialized**, **function compiler** for accelerating **numerically-focused** Python:\n",
    "\n",
    "- **Function compiler**: Numba compiles Python functions, not entire applications, and not parts of functions. Numba does not replace your Python interpreter, but is just another Python module that can turn a function into a (usually) faster function.\n",
    "\n",
    "- **Type-specializing**: Numba speeds up a function by generating a specialized implementation for the specific data types you're using. Python functions are designed to operate on generic data types, which makes them very flexible, but also very slow. In practice, you'll only call a function with a small number of argument types, so Numba will generate a fast implementation for each set of input types.\n",
    "\n",
    "- **Just-in-time (JIT)**: Numba translates functions when they are first called. This ensures the compiler knows what argument types you will be using. This also allows Numba to be used interactively in a Jupyter notebook just as easily as a traditional application.\n",
    "\n",
    "- **Numerically-focused**: Currently, Numba is focused on numerical data types, like `int`, `float`, and `complex`. There is some limited support for string processing. To get best results with Numba, you will likely be using NumPy arrays.\n",
    "\n",
    "Speedups range from approximately 2x (compared to simple NumPy code) to 200x (compared to pure Python). Note that Numba is not a replacement for the standard CPython interpreter (like e.g. [PyPy](https://pypy.org/)) and is not a Python-to-C/C++ translator (like e.g. [Cython](https://cython.org/)).\n",
    "\n",
    "Numba is *not* likely to help when:\n",
    "\n",
    "- Whole program compilation\n",
    "\n",
    "- Critical functions have already been converted to C or optimized Cython\n",
    "\n",
    "- Algorithms are not primarily numerical (exception: Numba does pretty well with bit manipulation. See the [Fastparquet](https://github.com/dask/fastparquet) library.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User interface\n",
    "\n",
    "[ [Back to top](#Outline) ]\n",
    "\n",
    "Numba's user interface is very straightforward, you decorate functions you want Numba to compile with the decorators provided by Numba:\n",
    "\n",
    "- `@jit` - Compiles function on-the-fly to produce efficient machine code [[docs](https://numba.pydata.org/numba-doc/latest/user/jit.html)].\n",
    "- `@vectorize` - Produces NumPy `ufunc`s (with all the `ufunc` methods supported) [[docs](https://numba.pydata.org/numba-doc/latest/user/vectorize.html#vectorize)].\n",
    "- `@guvectorize` - Produces NumPy generalized `ufunc`s [[docs](https://numba.pydata.org/numba-doc/latest/user/vectorize.html#guvectorize)].\n",
    "- `@stencil` - Declare a function as a kernel for a stencil like operation [[docs](https://numba.pydata.org/numba-doc/latest/user/stencil.html#numba-stencil)].\n",
    "- `@jitclass` - For `jit` aware classes [[docs](https://numba.pydata.org/numba-doc/latest/user/jitclass.html#jitclass)].\n",
    "- `@cfunc` - Declare a function for use as a native call back (to be called from C/C++ etc) [[docs](https://numba.pydata.org/numba-doc/latest/user/cfunc.html#cfunc)].\n",
    "- `@overload` - Register your own implementation of a function for use in `nopython` mode, e.g. `@overload(scipy.special.j0)` [[docs](https://numba.pydata.org/numba-doc/latest/extending/high-level.html#high-level-extending)]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def add(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add(1, 1)    # Compiles add function for (int64, int64) inputs and executes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add(3.4, 9.2)    # Compiles add function for (float64, float64) inputs and executes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Numba works\n",
    "\n",
    "[ [Back to top](#Outline) ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "    <img src=\"images/architecture.svg\"\n",
    "         align=\"center\"\n",
    "         width=\"70%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information about Numba's internals, I highly recommend checking out the [documentation on Numba's architecture](https://numba.pydata.org/numba-doc/dev/developer/architecture.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numba returns a dispatcher object which, when called, will compile the underlying Python function to machine code and return the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callable(add)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a user's perspective, this looks and acts just like a normal Python function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original Python function is stored in the `.py_func` attribute of the compiled function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add.py_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add.py_func(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the `.inspect_types()` method to display an annotated version of the function source code for each set of input types which has been compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add.inspect_types()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When things go wrong$^*$\n",
    "\n",
    "[ [Back to top](#Outline) ]\n",
    "\n",
    "Like all of us, Numba is not perfect. It doesn't support all Python language features or all objects from third-party libraries. For example, let's try to use our `add` function for adding two Pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_1 = pd.DataFrame({'a': [0, 1, 2, 3],\n",
    "                     'b': [4, 5, 6, 7]})\n",
    "\n",
    "df_2 = pd.DataFrame({'a': [8, 9, 10, 11],\n",
    "                     'b': [12, 13, 14, 15]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the Python interpreter we can add DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 + df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about using our Numba-compiled `add` function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add(df_1, df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at `inspect_types` again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add.inspect_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add.signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a `(pyobject, pyobject)` signature! That's because Numba doesn't support Pandas DataFrames and so `add(df_1, df_2)` was compiled in \"object mode\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Compilation modes\n",
    "\n",
    "Numba has two distinct compilation modes: `nopython` mode and `object` mode.\n",
    "\n",
    "#### `nopython` mode\n",
    "\n",
    "When compiling a function, Numba will try to infer all the types for every variable encountered. This is called `nopython` mode (i.e. able to replace all Python `PyObject`s with types supported by Numba). Numba will operate in `nopython` mode by default. However, if type inference fails then Numba will go back and treat all variables as `PyObject` types. This is called `object` mode.\n",
    "\n",
    "#### `object` mode\n",
    "\n",
    "Numba-compiled functions in `object` mode treat all values as Python `PyObject`s and use the Python C API to perform all operations on these objects. As such, functions compiled in `object` mode typically aren't much faster than normal Python. Speedups come when all types can be interred.\n",
    "\n",
    "To prevent the falling back to `object` mode, and instead raise an error, you can use `@jit(nopython=True)`. This is used so often that there's a separate decorator `@njit` which is just an alias for `@jit(nopython=True)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "NOTE: Falling back to `object` mode by default is going through a [depreciation cycle](http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit) and will be turned off in the `0.47.0` release of Numba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supported features\n",
    "\n",
    "Numba maintains a list of supported Python and NumPy features:\n",
    "\n",
    "- Python language features: http://numba.pydata.org/numba-doc/latest/reference/pysupported.html\n",
    "  \n",
    "- NumPy features: http://numba.pydata.org/numba-doc/latest/reference/numpysupported.html\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Additional `jit` options\n",
    "\n",
    "[ [Back to top](#Outline) ]\n",
    "\n",
    "The `@jit` decorator takes optional keyword arguments that offer some additional compilation features:\n",
    "\n",
    "### `cache`\n",
    "\n",
    "Option to save compiled function machine code to a file. By default on-disk caching is disabled. This allows you to avoid repeating the Numba compilation step in future Python sessions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(cache=True)\n",
    "def add_cached(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_cached(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the next time I start up this notebook and run `add_cached`, the cached machine code will be used instead of recompiling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### `nogil`\n",
    "\n",
    "Option to have Numba-compiled function release the [global interpreter lock (GIL)](https://docs.python.org/glossary.html#term-global-interpreter-lock) while they are being executed. This allows you to take advantage of multi-core systems by running Numba code concurrently with other threads executing Python or Numba code. By default releasing the GIL is disabled.\n",
    "\n",
    "It's worth noting that setting `nogil=True` does not make your code thread-safe, it just simply releases the GIL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(a):\n",
    "    trace = 0\n",
    "    for i in range(a.shape[0]):\n",
    "        trace += np.cos(a[i, i])\n",
    "    return a + trace\n",
    "\n",
    "calculate_gil = njit(calculate)                   # Will not release the GIL\n",
    "calculate_nogil = njit(nogil=True)(calculate)     # Will release the GIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.random((5_000, 5_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(calculate_gil(a), calculate_nogil(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `concurrent.futures` module to launch a thread pool and execute Python function calls asynchronously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 5 -n 1\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    results = list(executor.map(calculate_gil, [a] * 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 5 -n 1\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    results = list(executor.map(calculate_nogil, [a] * 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running in two threads with the GIL released avoids any GIL contention issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `parallel`\n",
    "\n",
    "Option to enables automatic parallelization (and related optimizations) for operations in the function known to have parallel semantics. You can consult the Numba's [automatic parallel docs](https://numba.pydata.org/numba-doc/dev/user/parallel.html) for a list of supported operations which Numba will attempt to parallelize.\n",
    "\n",
    "You can also also construct explicit parallel loops using Numba‚Äôs `prange` instead of `range`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import prange\n",
    "\n",
    "@njit(parallel=True)\n",
    "def parallel_sum(a):\n",
    "    s = 0\n",
    "    # Without \"parallel=True\" in the jit-decorator\n",
    "    # the prange statement is equivalent to range\n",
    "    for i in prange(a.shape[0]):\n",
    "        s += a[i]\n",
    "    return s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.random(1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating custom `ufunc`s with `@vectorize`\n",
    "\n",
    "[ [Back to top](#Outline) ]\n",
    "\n",
    "Numba provides an `@vectorize` decorator ([documentation](https://numba.pydata.org/numba-doc/dev/user/vectorize.html)) for generating custom `ufunc`s from Python functions. This is great for when you need something that isn't already implemented as an efficient `ufunc` in NumPy. For example, NumPy does not have a `ufunc` for the `logit` function:\n",
    "\n",
    "$\\mathrm{logit}(x) = \\log\\Big(\\frac{p}{1 - p}\\Big)$\n",
    "\n",
    "Let's write a Python implementation of `logit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def logit(a):\n",
    "    return math.log(a / (1 - a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works on scalars just fine, but not NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit(0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...let's make a `logit` a `ufunc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import vectorize\n",
    "\n",
    "@vectorize\n",
    "def logit_vec(a):\n",
    "    return math.log(a / (1 - a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.random(1_000_000)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_vec(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéâ ‚ö° üêç\n",
    "\n",
    "To fully appreciate what just happened, see the [NumPy docs for creating a custom `ufunc`](https://docs.scipy.org/doc/numpy/user/c-info.ufunc-tutorial.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where and when to use Numba\n",
    "\n",
    "[ [Back to top](#Outline) ]\n",
    "\n",
    "### Step 0\n",
    "\n",
    "Determine if your existing code is already sufficient. Don't optimize if you don't have to.\n",
    "\n",
    "### Step 1\n",
    "\n",
    "Profile your code using tools like [`cProfile`](https://docs.python.org/3/library/profile.html#module-cProfile), [`line_profiler`](https://github.com/rkern/line_profiler), or [`snakeviz`](https://jiffyclub.github.io/snakeviz/). This will measure execution times for invidiual parts of your code. \n",
    "\n",
    "### Step 2\n",
    "\n",
    "From profiling your code try to identify bottlenecks that would be useful to speed up. Are they already well-encapsulated functions? If not, can they be?\n",
    "\n",
    "### Step 3\n",
    "\n",
    "`jit` the bottlenecks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numba in action! UMAP\n",
    "\n",
    "[ [Back to top](#Outline) ]\n",
    "\n",
    "\n",
    "I thought it would be instructive to see an example of how Numba is used out in the wild. Let's looks at Uniform Manifold Approximation and Projection, or [UMAP](https://umap-learn.readthedocs.io/en/latest/), which is a dimensionality reduction technique that can be used search for a low dimensional projection of the data that has the closest possible equivalent fuzzy topological structure.\n",
    "\n",
    "Although it's somewhat outside the scope of this talk, if you're interested in learning more about UMAP, I highly recommend watching Leland McInnes' talk at SciPy 2018 on [YouTube](https://www.youtube.com/watch?v=nq6iPZVUxZU). It's very good.\n",
    "\n",
    "Example from https://umap-learn.readthedocs.io/en/latest/basic_usage.html#digits-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_array = plt.subplots(20, 20, figsize=(10, 10))\n",
    "axes = ax_array.flatten()\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(digits.images[i], cmap='gray_r')\n",
    "plt.setp(axes, xticks=[], yticks=[], frame_on=False)\n",
    "plt.tight_layout(h_pad=0.5, w_pad=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UMAP implements the familiar scikit-learn `.fit` / `.transform` interface that we can use to learn an embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "embedding = umap.UMAP(random_state=2).fit_transform(digits.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some code to make an interactive plot using [Bokeh](https://bokeh.org/)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba_talk import plot_embedding\n",
    "plot_embedding(embedding, digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the source code for UMAP, we can see Numba is used to calculate distance metrics and implement custom algorithms in [umap/distances.py](https://github.com/lmcinnes/umap/blob/74a7b3e75362fa6eb3318a292e5364c12c43df62/umap/distances.py) and [umap/umap_.py](https://github.com/lmcinnes/umap/blob/74a7b3e75362fa6eb3318a292e5364c12c43df62/umap/umap_.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "[ [Back to top](#Outline) ]\n",
    "\n",
    "- Numba is an open source JIT compiler for Python functions\n",
    "\n",
    "- Currently it's primarily concerned with numerically-focused Python\n",
    "\n",
    "- It accelerates your existing Python functions with minimal code modifications\n",
    "\n",
    "- Identify performance bottlenecks in your code and try decorating with `@jit`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[ [Back to top](#Outline) ]\n",
    "\n",
    "- [Numba documentation](https://numba.pydata.org/numba-doc/latest/)\n",
    "\n",
    "- There are lots of great tutorials and talks about Numba online. In particular, I suggest checking out:\n",
    "\n",
    "    - \"Numba GPU tutorial\" at PyData Amsterdam 2019 by Valentin Haenel [[GitHub](https://github.com/esc/pydata-amsterdam2019-numba)][[YouTube](https://www.youtube.com/watch?v=CQDsT81GyS8)] <-- thanks Val for letting me use some of your talk materials\n",
    "    \n",
    "    - \"How to Accelerate an Existing Codebase with Numba\" at SciPy 2019 by Siu Kwan Lam & Stanley Seibert [[YouTube](https://www.youtube.com/watch?v=-4tD8kNHdXs)]\n",
    "\n",
    "    - \"Numba: Tell those C++ bullies to get lost\" SciPy 2017 tutorial by Gil Forsyth & Lorena Barba [[GitHub](https://github.com/gforsyth/numba_tutorial_scipy2017)][[YouTube](https://www.youtube.com/watch?v=1AwG0T4gaO0)]\n",
    "\n",
    "- [Why Python is Slow: Looking Under the Hood](https://jakevdp.github.io/blog/2014/05/09/why-python-is-slow/) by Jake VanderPlas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "[ [Back to top](#Outline) ]\n",
    "\n",
    "\n",
    "- GitHub: https://github.com/numba/numba\n",
    "\n",
    "- Documentation: https://numba.pydata.org/numba-doc/latest/\n",
    "\n",
    "- Community:\n",
    "\n",
    "    - Gitter chat room: https://gitter.im/numba/numba\n",
    "    \n",
    "    - Mailing list: https://groups.google.com/a/continuum.io/d/forum/numba-users\n",
    "    \n",
    "    - As a note, I've been really impressed how responsive both the core developers and the community as a whole have been on the Gitter channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you!\n",
    "\n",
    "### Questions?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "rise": {
   "auto_select": "code",
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
